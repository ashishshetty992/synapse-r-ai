Phase-3: AI/ML Neuron Layer + Planner Integration â€” Status Checklist

0) Ground Truth & North Star
	â€¢	âœ… Clear goal: AI-assisted runtime (intentâ†’schema, safe UQL, MySQL+Mongo, indexes/parity/policy).
	â€¢	âœ… Success criteria defined (Exit Criteria & Metrics list).

Action: none.

â¸»

1) Neurons Service (FastAPI) & Contracts
	â€¢	âœ… FastAPI app skeleton: /iem/build, /intent/encode, /synapse/match.
	â€¢	âœ… Pydantic models for request/response.
	â€¢	âœ… External uem.json (no hardcoding) â†’ produces iem.json.
	â€¢	âœ… Runs locally (no Docker).
	â€¢	âœ… Minimal error handling & input validation (happy-path only).
	â€¢	âœ… Auth / rate limits / structured JSON logging.

Action: add robust validators (bad payloads, missing files), request-id logs, JSON logs.

â¸»

2) Neuron-1: Schema Understanding (IEM)
	â€¢	âœ… Field embeddings (char-ngrams) + role priors (id/timestamp/money/geo/category/text/qty).
	â€¢	âœ… Alias generation (underscored â†” spaced).
	â€¢	âœ… Deterministic iem.json (configurable dim).
	â€¢	âœ… Quality checks (ids cluster; amounts cluster) computed & surfaced via /iem/verify.
	â€¢	âœ… IEM versioning & drift detection (compare IEM_t vs IEM_t-1).
	â€¢	âœ… Entity-level embeddings.

Formula Lab
	â€¢	âœ… F1 RoleBoostâ„¢ (role-aware vector: vâ€² = normalize(v + Î»áµ£Â·RÂ·r)) â†’ emit roleBoost per field.
	â€¢	âœ… F2 AliasStabilityâ„¢ (drift guard; feeds S(p)).

Action: âœ… COMPLETE - /iem/verify endpoint implemented (main.py:699) reporting clustering scores, roleBoost stats, and drift alerts.

â¸»

3) Neuron-2: Intent Encoder
	â€¢	âœ… Encoder v0.2 (IQL â†’ vector via char-ngrams bag).
	â€¢	âœ… /intent/encode returns {vec, vocab}.
	â€¢	âœ… /intent/encode_nl (NL text â†’ vector) with synonyms injection (main.py:609).
	â€¢	âœ… synonyms.json (e.g., "revenueâ†’total_amount", "cityâ†’shipping_city").

Formula Lab
	â€¢	âœ… F6 SynoMixâ„¢ (BM25 alias score âŠ• cosine; boosts A(p) for NLQ) - implemented in intent.py:309.

Action: âœ… COMPLETE - /intent/encode_nl + synonyms.json shipped; top alias hits logged in debug.topAliasHits.

â¸»

4) Neuron-3: Synapse Matching
	â€¢	âœ… Cosine ranking over IEM fields/entities.
	â€¢	âœ… Tunables: topKFields, topKEntities, roleAlpha.
	â€¢	âœ… Slot-filling rules exposed via /synapse/fill API (main.py:867).
	â€¢	âœ… Conflict resolver (multi "city" across entities) - implemented in synapse.py.
	â€¢	ğŸŸ¨ Conflict transparency: selectedBy, decisionScore, bestNumericScore at top level âœ…; finalScore and reason only per-candidate in scores[] (not top-level) - partial (synapse.py:906-928, models.py:218-226).
	â€¢	âœ… Timestamp behavior: sameEntityTimestampPrior + locality decay (0.4Ã— prior for 1-hop) + preferSameEntityTimestampDelta override live (synapse.py:777-790, 878-895, 1154-1190).
	â€¢	âœ… Join inference beyond single-hop (see Â§7).

Formula Lab
	â€¢	âœ… F3 AlignPlusâ„¢ (coverage-aware A(p)): log {A_base, Coverage, OffSchemaRate, Aâº} - computed in synapse.py:527.
	â€¢	âœ… F4 PathScoreâ„¢ (scores multi-join paths) - implemented in synapse.py:_path_score.

Action: âœ… COMPLETE - /synapse/fill (main.py:867) and /synapse/paths (main.py:1056) endpoints implemented with edge breakdowns, normalized scores, and guardrails.

â¸»

5) Neuron-4: Auto-Question Generator (PoC)
	â€¢	âœ…  Prototype spec (top_k / trend / compare) only.
	â€¢	âœ…  /generate â†’ 5 IQLs per schema (main.py:1347).
	â€¢	âœ…  Validate with ops/validate-examples.js, write examples/aiql/.
	â€¢	âœ…  Coverage endpoint /examples/coverage (main.py:1341).

Action: âœ… COMPLETE - /generate implemented, writes files, validator passes, coverage captured.

â¸»
Neuron-5: Plan & Checklist

ğŸ¯ Goals (what Neuron-5 adds)
	â€¢	Learn from real prompts + chosen targets to improve matching.
	â€¢	Support few-shot guidance per tenant/domain (no code redeploy).
	â€¢	Autotune role/alias/metric shaping with safe boundaries.
	â€¢	Continuous evaluation on golden sets with drift alerts.
	â€¢	Versioned models/configs with rollback.

â¸»

ğŸ§© Components to Build
	â€¢	Feedback Store (append-only):
	â€¢	âœ… File: phase3-neurons/data/feedback.jsonl (one JSON per line)
	â€¢	âœ… Schema: {ts, tenant, intent, chosenTarget, otherSlots, iemHash, userAgent, latencyMs}
	â€¢	âœ… API: POST /feedback/record (feedback.py:14)
	â€¢	Golden Set (curated eval):
	â€¢	âœ… Dir: phase3-neurons/golden/ (e.g., orders-top-city.json)
	â€¢	âœ… Schema: {intent, expected: {target, slots{}}, notes}
	â€¢	âœ… API: GET /golden/list, POST /golden/add (golden.py:20,34)
	â€¢	Trainer (few-shot + weights search):
	â€¢	âœ… Module: app/trainer.py
	â€¢	âœ… Inputs: feedback.jsonl, golden/
	â€¢	âœ… Outputs:
	â€¢	âœ… app/checkpoints/trainer_{yyyymmddHHMM}/shaping.json
	â€¢	âœ… app/checkpoints/.../fewshot.json
	â€¢	âœ… Strategy:
	â€¢	âœ… rank-loss on chosenTarget vs candidates
	â€¢	âœ… small-grid search over {alias_alpha, shape_alpha, shape_beta, metric_alpha, role_alpha_default}
	â€¢	âœ… per-tenant deltas on top of global defaults
	â€¢	Few-Shot Runtime Booster:
	â€¢	âœ… File: app/fewshot.py
	â€¢	ğŸŸ¨ Loads fewshot.json and nudges role/alias priors at /intent/encode_nl & /synapse/match (loaded but not actively applied in matching).
	â€¢	âœ… Merge order: global â†’ tenant â†’ request.overrides
	â€¢	Evaluator:
	â€¢	âœ… Module: app/eval.py
	â€¢	âœ… Metrics: Top-1 acc, MRR, Role hit@1, Slot F1, Aplus mean, PathScore mean
	â€¢	âœ… API: GET /trainer/last_eval (trainer.py:241) - writes canonical last_eval.json, returns {ok, checkpoint, ...}
	â€¢	Versioning + Rollback:
	â€¢	âœ… API: GET /trainer/versions (trainer.py:217), POST /trainer/activate (trainer.py:198)
	â€¢	â›” POST /trainer/rollback - not implemented
	â€¢	âœ… Active pointers saved in phase3-neurons/runtime/active.json

â¸»

ğŸ”Œ Public APIs (new)
	â€¢	âœ… POST /feedback/record (feedback.py:14)
Body: {intent, chosenTarget, slots?, tenant?} â†’ {ok, id}
	â€¢	âœ… POST /trainer/run (trainer.py:102)
Body: {tenant?, maxGrid=64, maxFewshot=2000} â†’ {ok, ckpt, metrics}
	â€¢	âœ… POST /trainer/activate (trainer.py:198)
Body: {checkpoint} â†’ {ok, active}
	â€¢	âœ… GET /trainer/versions (trainer.py:217) â†’ list of checkpoints + metrics
	â€¢	âœ… GET /trainer/last_eval (trainer.py:241) â†’ metrics for active ckpt, writes canonical last_eval.json, returns {ok, checkpoint, ...}
	â€¢	âœ… GET /fewshot/show?tenant=â€¦ (fewshot.py:9) â†’ preview applied few-shot patterns

â¸»

âš™ï¸ Config & Files
	â€¢	shaping.json (trained) â†’ app/checkpoints/.../shaping.json
	â€¢	weights.alias_alpha, shape_alpha, shape_beta, metric_alpha, role_alpha_default
	â€¢	pathScoring.idPrior, fkBonus, lengthPriorBase, cosineWeight
	â€¢	alignPlus.osrZeroWhenNoText

		â€¢	fewshot.json (trained):

		{
  "global": {
    "hints": [{"tokens":["gmv","revenue"], "boost":{"role":"money", "delta":0.03}}],
    "aliases": {"gmv":"revenue"}
  },
  "tenants": {
    "acme": {
      "hints": [{"tokens":["cz"], "boost":{"role":"geo", "delta":0.02}}]
    }
  }
}

	â€¢	runtime/active.json

		{"checkpoint":"trainer_2025-10-28_1405","shaping":"â€¦/shaping.json","fewshot":"â€¦/fewshot.json"}

ğŸ› ï¸ CLI / Make / NPM
	â€¢	â›” make feedback-demo â†’ seeds 20 feedback rows - not implemented
	â€¢	â›” make trainer-run â†’ runs trainer, prints ckpt + metrics - not implemented
	â€¢	â›” make trainer-activate CKPT=â€¦ - not implemented
	â€¢	â›” npm run train â†’ POST /trainer/run (global) - not implemented
	â€¢	â›” npm run train:tenant -- acme - not implemented
	â€¢	â›” npm run trainer:activate -- trainer_YYYYMMDDHHMM - not implemented

â¸»

âœ… QA & Validation
	â€¢	Offline eval (mandatory pass gates):
	â€¢	Top-1 accuracy: +â‰¥5% vs baseline or reject
	â€¢	Aplus mean: +â‰¥3% or neutral
	â€¢	No entity drift: PathScore median within Â±10%
	â€¢	AB Shadow:
	â€¢	Header x-experiment: train-shadow returns both baseline & trained scores in debug
	â€¢	Kill-switch: TRAINER_SHADOW_ONLY=true
	â€¢	Canaries:
	â€¢	Tenant allowlist env: TRAINER_TENANT_CANARY="acme,shipyaari"

â¸»

ğŸ” Observability
	â€¢	âœ… Structured logs: trainer.run.start/end, trainer.ckpt.activate, fewshot.load (via log_json in main.py)
	â€¢	âœ… GET /metrics Prom-style gauges (main.py:53-59):
	â€¢	âœ… synapse_trainer_top1_acc{tenant=â€¦}
	â€¢	âœ… synapse_trainer_runs_total
	â€¢	âœ… synapse_feedback_rows_total

â¸»

ğŸ§¯ Guardrails
	â€¢	âœ… Bound weights search ranges (e.g., alias_alpha âˆˆ [0.25, 0.6]) - implemented in trainer.py with clamp()
	â€¢	âœ… PII filter for feedback payloads (no raw user text stored if marked sensitive) - feedback.py:20-22
	â€¢	âœ… Tenant isolation: disk paths under checkpoints/{tenant|_global_}/â€¦ - implemented in trainer.py:_tenant_dir()

â¸»

ğŸš€ Rollout Plan
	1.	Land Feedback Store + /feedback/record.
	2.	Add evaluator on existing golden from Neuron-4 /generate.
	3.	Implement trainer (grid search + few-shot extraction).
	4.	Expose activate/rollback + shadow-AB headers.
	5.	Enable canary tenants only; watch metrics.
	6.	Expand to all tenants; schedule weekly re-train.

â¸»

ğŸ”­ Stretch (optional)
	â€¢	Active Learning: auto-sample low-confidence conflicts into a review queue.
	â€¢	Contrastive Fine-Tuning: learn a small projection on top of the IEM space (kept local).
	â€¢	Meta-Learner: per-ask policy (top_k vs trend) to set shaping weights dynamically.

â¸»


â¸»

6) Planner Integration (A/C/P/S/R with Beam)
	â€¢	âœ… Formula defined; default weights documented.
	â€¢	ğŸŸ¨ Trace shows planner params & slot candidates; missing A/C/P/S/R numbers in planner trace.
	â€¢	ğŸŸ¨ A(p) computed via AlignPlus in synapse.py but not fully wired into planner trace.
	â€¢	ğŸŸ¨ C(p) hinted by adapter errors (unindexed ranges) but not scored via CostPlus formula.
	â€¢	ğŸŸ¨ P(p) simple penalty concept in planner; not consistently applied.
	â€¢	ğŸŸ¨ S(p) (alias brittleness) computed in /iem/verify but not wired into planner.
	â€¢	â›” R(p) (parity/RBAC) not computed.
	â€¢	âœ… Boltzmann exploration (Ï„) in beam selection (planner/src/index.ts:464 softmaxPick with tau).

Formula Lab
	â€¢	âœ… F3 AlignPlusâ„¢ â†’ A(p) - implemented in synapse.py:527, used in /synapse/fill
	â€¢	â›” F8 CostPlusâ„¢ â†’ C(p) - formula not implemented in planner
	â€¢	â›” F5 GroupInfoâ„¢ â†’ P(p) - formula not implemented in planner
	â€¢	âœ… F2 AliasStabilityâ„¢ â†’ S(p) - computed in iem.py:237, available via /iem/verify but not wired to planner
	â€¢	â›” F7 ParityTauâ„¢ â†’ R(p) - not implemented

Action: wire AlignPlus/AliasStability into planner trace; implement CostPlus/GroupInfo/ParityTau formulas; log {A,C,P,S,R,weights,final,Ï„} in planner trace.

â¸»

7) Schema Graph & Multi-Join Reasoning
	â€¢	âœ… Single-hop join working (sales_order â†” customer) â€” proven.
	â€¢	ğŸŸ¨ Build graph.json (entities + edges: FK=1.0, heuristics<1.0) - graph built in-memory via _build_join_graph() but not persisted to graph.json file.
	â€¢	âœ… find_paths(source,target,max_depth=3) + PathScore ranking - implemented in synapse.py:_bfs_paths() and _path_score().
	â€¢	ğŸŸ¨ Join path disambiguation using Aâº/C/S - paths scored but not disambiguated using full Aâº/C/S blend.

Formula Lab
	â€¢	âœ… F4 PathScoreâ„¢ (semantics + index + fanout + hop cost) - implemented in synapse.py:_path_score() with edge breakdowns.

Action: âœ… /synapse/paths endpoint shipped (main.py:1056) with edge breakdowns, normalized scores, guardrails. Add graph.json persistence; wire Aâº/C/S for path disambiguation.

â¸»

8) Multi-GroupBy & Complex Query Shapes
	â€¢	âœ… Single & dual groupBy (segmentÃ—country; city over periods).
	â€¢	ğŸŸ¨ Triple groupBy tests (MySQL GROUP BY list, Mongo composite _id) â€” not in suite.
	â€¢	ğŸŸ¨ Compare periods Ã— extra dims (periodÃ—segmentÃ—country) â€” missing tests.
	â€¢	â›” Window functions (moving avg, YoY) â€” defer to Phase-4.
	â€¢	ğŸŸ¨ Nested AND/OR across joins â€” partial coverage.

Formula Lab
	â€¢	â›” F5 GroupInfoâ„¢ (parsimony vs informativeness) to score group sets.

Action: add 3Ã— groupBy examples; AND/OR precedence cases on both engines; log P(p)/InfoGainÌ‚.

â¸»

9) Integration with Phase-2 Runtime
	â€¢	âœ… E2E proven: orders.* (neuron) â†’ sales_order.* UQL/SQL; MySQL & Mongo OK.
	â€¢	âœ… x-intent-vec path works for compile/query.
	â€¢	ğŸŸ¨ Feature flag USE_NEURONS=1 (toggle planner) â€” not plumbed.
	â€¢	ğŸŸ¨ Trace: add A/C/P/S/R everywhere.
	â€¢	â›” Fallback policy (low neuronScore â†’ rule planner + log).

Action: add flag + fallback; propagate Formula Lab values to trace.

â¸»

10) Parity, Index Safety & Policy
	â€¢	âœ… Parity endpoint works; minor ordering diffs acceptable.
	â€¢	âœ… Index guard requireIndexedFilters=true active.
	â€¢	ğŸŸ¨ Feed index/complexity hints into CostPlusâ„¢.
	â€¢	â›” RBAC allowlist + penalties into R(p).

Formula Lab
	â€¢	â›” F7 ParityTauâ„¢ (Kendall Ï„ from sampled parity) â†’ R(p).
	â€¢	â›” F8 CostPlusâ„¢ (unindexed_range, join_depth, like_contains, non_sargable, est_rows).

Action: emit hints from adapters; compute Ï„_K from parity sample; wire to C(p)/R(p).

â¸»

11) Tests & Tooling
	â€¢	âœ… Phase-2 exerciser extended; both engines + extras run.
	â€¢	âœ… Examples validate against schema.
	â€¢	â›” run-phase3-tests.sh invoking neurons: /iem/build, /iem/verify, /intent/encode(_nl), /synapse/match, /synapse/paths, /synapse/fill, /generate.
	â€¢	â›” Assertions: compiled UQL runs; traces contain {A,C,P,S,R,Ï„}; multi-join & 3Ã— groupBy cases; parity Ï„_K present.

Action: add phase-3 runner + summary.

â¸»

12) Documentation & Operability
	â€¢	ğŸŸ¨ Phase-3 Test Report template (like Phase-1/2) - COMPREHENSIVE_TEST_RESULTS.txt exists.
	â€¢	ğŸŸ¨ README-neurons.md - basic README.md exists (phase3-neurons/README.md) but missing detailed wiring guide.
	â€¢	â›” Whitepaper appendix: A/C/P/S/R examples & weight sensitivity.

Action: enhance README with wiring guide; draft whitepaper appendix.

â¸»

Immediate Next Actions (surgical)
	1.	Planner scoring & trace: implement neuronScore() with F3/F5/F8; log {A,C,P,S,R,final,Ï„}.
	2.	Graph & paths: build graph.json, add find_paths() + F4 PathScoreâ„¢; ship /synapse/paths.
	3.	/synapse/fill: slot fill + join hints; add 3Ã— groupBy examples.
	4.	Intent NL: /intent/encode_nl + F6 SynoMixâ„¢; load synonyms.json.
	5.	Costs/Parity: adapter hints â†’ F8 CostPlusâ„¢; parity sample â†’ F7 ParityTauâ„¢.
	6.	Phase-3 runner: run-phase3-tests.sh invoking all neuron endpoints; collect traces & parity Ï„_K.


neuron 3 -  upgrade for future
```
Want a quick hardening pass? Three tiny upgrades (no behavioral change unless you use them):
	1.	Per-edge breakdown in /synapse/paths debug
Add an array like:"edgeScores": [
  {"edge":"payment.order_idâ†’orders.id","cosine":0.24,"idPrior":0.10,"fkBonus":0.05,"lengthPrior":0.90,"final":0.3215}
] 
â€¦so you can see why a path scored what it did.
	2.	Normalized score (0â€“1) alongside raw
Return scoreNorm = min(1, max(0, score)) so UI sliders feel consistent across settings.
	3.	Guardrails for overrides
Clamp cosineWeightâˆˆ[0,1], lengthPriorBaseâˆˆ[0.5,1.0], idPrior,fkBonusâˆˆ[0,0.5]. If an override is out of range, echo a warning in debug.warn.

If you like, Iâ€™ll patch those in next. Otherwise we can move on to the next neuron (or wire the tiny Formula Lab â€“ PathScore panel with sliders for cosineWeight / idPrior / fkBonus / lengthPriorBase and live previews).
```

ğŸ’¡ Future: Let Nauvra Learn This

In Phase-4 (Neuro-Symbolic Learning) we'll train a lightweight Conflict Resolver MLP that:
	â€¢	takes (metricVec, candidateVec, pathFeatures)
	â€¢	learns to predict the most probable relationally consistent slot,
	â€¢	and fine-tunes the weight blend (0.5/0.3/0.2 â†’ learned dynamically).

That's when the resolver becomes self-tuning rather than heuristic.

â¸»

ğŸ“‹ REVIEW SUMMARY (Codebase Review 2025-01-XX)

âœ… NEWLY DISCOVERED IMPLEMENTATIONS:
	â€¢	/iem/verify endpoint fully implemented (main.py:699) - reports clustering, roleBoost, drift
	â€¢	/synapse/paths endpoint with edge breakdowns, normalized scores, guardrails (main.py:1056)
	â€¢	/synapse/fill endpoint fully implemented (main.py:867) with AlignPlus computation
	â€¢	Neuron-5 APIs mostly complete: feedback, golden, trainer, eval, fewshot endpoints exist
	â€¢	Boltzmann exploration (Ï„) already implemented in planner beam selection
	â€¢	Prometheus metrics infrastructure in place (main.py:53-59)
	â€¢	PII filtering and tenant isolation implemented

ğŸŸ¨ PARTIAL IMPLEMENTATIONS:
	â€¢	Few-shot hints loaded but not actively applied in matching runtime
	â€¢	AlignPlus computed but not fully wired into planner trace
	â€¢	AliasStability computed but not wired into planner S(p)
	â€¢	Graph built in-memory but not persisted to graph.json
	â€¢	Path disambiguation doesn't use full Aâº/C/S blend

â›” MISSING ITEMS:
	â€¢	POST /trainer/rollback endpoint
	â€¢	CLI/Make/NPM commands for trainer operations
	â€¢	run-phase3-tests.sh test runner
	â€¢	CostPlus (F8) formula in planner
	â€¢	GroupInfo (F5) formula in planner
	â€¢	ParityTau (F7) formula for R(p)
	â€¢	RBAC penalties into R(p)
	â€¢	Feature flag USE_NEURONS=1 end-to-end wiring
	â€¢	Fallback policy (low neuronScore â†’ rule planner)
	â€¢	graph.json persistence
	â€¢	Enhanced README with wiring guide
	â€¢	Whitepaper appendix

ğŸ” FILES TO MODIFY FOR COMPLETION:
	â€¢	packages/planner/src/index.ts - wire A/C/P/S/R into trace
	â€¢	packages/planner/src/scorer.ts - implement CostPlus, GroupInfo formulas
	â€¢	phase3-neurons/app/synapse.py - wire few-shot hints into match_candidates
	â€¢	phase3-neurons/app/intent.py - wire few-shot hints into encode_intent_nl
	â€¢	phase3-neurons/app/trainer.py - add rollback endpoint
	â€¢	phase3-neurons/app/synapse.py - add graph.json persistence
	â€¢	Makefile / package.json - add CLI commands
	â€¢	ops/run-phase3-tests.sh - create test runner
	â€¢	phase3-neurons/README.md - enhance with wiring guide

=================================================
=================================================
Neuron-6: Curiosity & Insight Engine â€” Status Checklist

0) Core Intent (North Star)
	â€¢	Goal defined: Nauvra autonomously asks and answers â€œwhatâ€™s changing, breaking, or leakingâ€ without human prompt.
	â€¢	Success metrics:
	â€¢	Discovery precision (how often an auto insight is correct & relevant).
	â€¢	Business impact rate (how often it reveals actionable issues before humans do).
	â€¢	Diversity (breadth of topics/entities touched weekly).
	â€¢	Compute cost vs value ratio (auto insights per $ of query budget).

â¸»

1) Data & Context Awareness
	â€¢	Access to IEM (schema roles & embeddings) â€” required.
	â€¢	Access to Graph.json (joins & relationships).
	â€¢	Access to Planner A/C/P/S/R scores (align, cost, group info, stability, parity).
	â€¢	Ability to read golden metrics (e.g., revenue, SLA, returns ratio, utilization).
	â€¢	Knows tenant-level thresholds (SLA, margin %, target times, etc).
	â€¢	Knows feedback signals from Neuron-5 (what humans found useful or irrelevant).

â¸»

2) Question Generation Layer
	â€¢	Implements Schema-driven generators â€” discovers joins and measure/dimension pairs (Orders Ã— Returns, Payment Ã— Courier).
	â€¢	Implements Anomaly generators â€” detects data drift, outliers, or sudden metric variance.
	â€¢	Implements Pattern generators â€” derives trends, deltas, ratios, seasonality, correlations.
	â€¢	Implements Coverage explorer â€” identifies under-queried schemas (cold zones).
	â€¢	Supports Goal-oriented seeds (predefined probes like â€œleakage,â€ â€œdelay,â€ â€œinefficiency,â€ â€œfraudâ€).
	â€¢	Stores candidate question templates in curiosity/pools/.

â¸»

3) Candidate Builder
	â€¢	Converts each question idea â†’ valid IQL (Intent Query Language).
	â€¢	Resolves metric, groupBy, and filters using IEM + Synapse Match.
	â€¢	Verifies join validity using PathScore and CostPlus.
	â€¢	Ensures all candidates pass safety: PII safe, indexed, RBAC-compliant.
	â€¢	Each candidate stored in curiosity/candidates.jsonl with {intent, IQL, score, reason}.

â¸»

4) Utility Scoring (Self-Evaluation)
	â€¢	Implements Utility function U(p) = f(A,C,P,S,R,Novelty,InfoGain).
	â€¢	Computes Novelty via vector distance from past 7-day insights.
	â€¢	Computes InfoGain via entropy / KL divergence over distributions.
	â€¢	Blends planner signals A/C/P/S/R with curiosity-specific weights.
	â€¢	Logs score breakdown per candidate in debug trace.
	â€¢	Rank & filter top-N for execution under cost/time budget.

â¸»

5) Execution & Result Evaluation
	â€¢	Executes top-N candidates (sample mode first, full mode on promising).
	â€¢	Captures runtime metrics (latency, rows, cost).
	â€¢	Computes Result Surprisingness Score (z-score, % delta vs baseline).
	â€¢	Tags candidates with insight type: anomaly / correlation / trend / leakage / SLA breach.
	â€¢	Writes outputs to curiosity/results/{date}/ as {IQL, insight_summary, metrics, explain}.
	â€¢	Updates feedback store with auto-generated results.

â¸»

6) Surfacing & Human Feedback Loop
	â€¢	/curiosity/feed endpoint showing auto insights ranked by Utility.
	â€¢	Each insight has: question, brief insight text, supporting chart, explanation (join, score breakdown).
	â€¢	/curiosity/feedback API â€” thumbs up/down or â€œirrelevant.â€
	â€¢	Feedback auto-feeds back to Neuron-5 trainer (few-shot delta).
	â€¢	Insights tagged by domain (Finance / SLA / Operations / Customer / Courier).

â¸»

7) Safety & Guardrails
	â€¢	Enforces query cost ceiling (C(p) < limit).
	â€¢	Suppresses or masks PII automatically.
	â€¢	Enforces parity check (R(p) within allowed bias threshold).
	â€¢	Throttles exploration via bandit scheduler (limits per hour/day).
	â€¢	Auditable logs: every auto insight has reproducible IQL + graph snapshot hash.
	â€¢	Canary mode: run for selected tenants first.

â¸»

8) Learning Loop
	â€¢	Accepted insights â†’ feedback store (positive).
	â€¢	Ignored/irrelevant insights â†’ negative samples.
	â€¢	Trainer re-weights novelty and InfoGain coefficients weekly.
	â€¢	Periodic retrain of curiosity weights (without redeploy).
	â€¢	Drift detector alerts when Utility distribution shifts (too repetitive or stale).

â¸»

9) Observability & Evaluation
	â€¢	Metrics exposed via /metrics:
	â€¢	curiosity_insights_generated_total
	â€¢	curiosity_useful_rate
	â€¢	curiosity_avg_cost_ms
	â€¢	curiosity_diversity_score
	â€¢	curiosity_learning_velocity
	â€¢	/curiosity/stats dashboard for ops visibility.
	â€¢	Phase-3 style test harness for evaluation.

â¸»

10) Stretch Goals
	â€¢	Hypothesis chaining â€” builds multi-step insights (â€œbecause Aâ†’Bâ†’Câ€).
	â€¢	Counterfactual generator â€” suggests â€œWhat if COD disabled?â€ or â€œWhat if zone rerouted?â€
	â€¢	Causal hinting â€” simple regression or difference-in-difference to test correlation strength.
	â€¢	Self-benchmarking â€” compares its insights vs human queries for overlap/novelty.

â¸»

Exit Criteria (Neuron-6 complete whenâ€¦)

âœ… It can autonomously propose & execute new IQLs daily
âœ… â‰¥60% of surfaced insights are novel (not duplicates of prior week)
âœ… â‰¥30% of insights rated â€œusefulâ€ by humans
âœ… No safety/policy violations (R(p), cost guard)
âœ… Insights reproducible (same IEM snapshot â†’ same result)
âœ… Trainer receives feedback from curiosity loop automatically