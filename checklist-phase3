Phase-3: AI/ML Neuron Layer + Planner Integration â€” Status Checklist

0) Ground Truth & North Star
	â€¢	âœ… Clear goal: AI-assisted runtime (intentâ†’schema, safe UQL, MySQL+Mongo, indexes/parity/policy).
	â€¢	âœ… Success criteria defined (Exit Criteria & Metrics list).

Action: none.

â¸»

1) Neurons Service (FastAPI) & Contracts
	â€¢	âœ… FastAPI app skeleton: /iem/build, /intent/encode, /synapse/match.
	â€¢	âœ… Pydantic models for request/response.
	â€¢	âœ… External uem.json (no hardcoding) â†’ produces iem.json.
	â€¢	âœ… Runs locally (no Docker).
	â€¢	âœ… Minimal error handling & input validation (happy-path only).
	â€¢	âœ… Auth / rate limits / structured JSON logging.

Action: add robust validators (bad payloads, missing files), request-id logs, JSON logs.

â¸»

2) Neuron-1: Schema Understanding (IEM)
	â€¢	âœ… Field embeddings (char-ngrams) + role priors (id/timestamp/money/geo/category/text/qty).
	â€¢	âœ… Alias generation (underscored â†” spaced).
	â€¢	âœ… Deterministic iem.json (configurable dim).
	â€¢	âœ… Quality checks (ids cluster; amounts cluster) computed & surfaced â€” implicit only, not reported.
	â€¢	âœ… IEM versioning & drift detection (compare IEM_t vs IEM_t-1).
	â€¢	âœ… Entity-level embeddings.

Formula Lab
	â€¢	âœ… F1 RoleBoostâ„¢ (role-aware vector: vâ€² = normalize(v + Î»áµ£Â·RÂ·r)) â†’ emit roleBoost per field.
	â€¢	âœ… F2 AliasStabilityâ„¢ (drift guard; feeds S(p)).

Action: add /iem/verify to report clustering scores, roleBoost stats, and drift alerts.

â¸»

3) Neuron-2: Intent Encoder
	â€¢	âœ… Encoder v0.2 (IQL â†’ vector via char-ngrams bag).
	â€¢	âœ… /intent/encode returns {vec, vocab}.
	â€¢	âœ… /intent/encode_nl (NL text â†’ vector) with synonyms injection.
	â€¢	âœ… synonyms.json (e.g., â€œrevenueâ†’total_amountâ€, â€œcityâ†’shipping_cityâ€).

Formula Lab
	â€¢	âœ… F6 SynoMixâ„¢ (BM25 alias score âŠ• cosine; boosts A(p) for NLQ).

Action: ship /intent/encode_nl + synonyms.json; log top alias hits.

â¸»

4) Neuron-3: Synapse Matching
	â€¢	âœ… Cosine ranking over IEM fields/entities.
	â€¢	âœ… Tunables: topKFields, topKEntities, roleAlpha.
	â€¢	âœ… Slot-filling rules exist conceptually; not exposed as API.
	â€¢	âœ… Conflict resolver (multi â€œcityâ€ across entities).
	â€¢	âœ… Join inference beyond single-hop (see Â§7).

Formula Lab
	â€¢	âœ… F3 AlignPlusâ„¢ (coverage-aware A(p)): log {A_base, Coverage, OffSchemaRate, Aâº}.
	â€¢	âœ… F4 PathScoreâ„¢ (scores multi-join paths).

Action: add /synapse/fill (slot fill + join hints) and /synapse/paths (path candidates + scores).

â¸»

5) Neuron-4: Auto-Question Generator (PoC)
	â€¢	âœ…  Prototype spec (top_k / trend / compare) only.
	â€¢	âœ…  /generate â†’ 5 IQLs per schema.
	â€¢	âœ…  Validate with ops/validate-examples.js, write examples/aiql/.

Action: implement /generate, write files, run validator, capture coverage.

â¸»
Neuron-5: Plan & Checklist

ğŸ¯ Goals (what Neuron-5 adds)
	â€¢	Learn from real prompts + chosen targets to improve matching.
	â€¢	Support few-shot guidance per tenant/domain (no code redeploy).
	â€¢	Autotune role/alias/metric shaping with safe boundaries.
	â€¢	Continuous evaluation on golden sets with drift alerts.
	â€¢	Versioned models/configs with rollback.

â¸»

ğŸ§© Components to Build
	â€¢	Feedback Store (append-only):
	â€¢	File: phase3-neurons/data/feedback.jsonl (one JSON per line)
	â€¢	Schema: {ts, tenant, intent, chosenTarget, otherSlots, iemHash, userAgent, latencyMs}
	â€¢	API: POST /feedback/record
	â€¢	Golden Set (curated eval):
	â€¢	Dir: phase3-neurons/golden/ (e.g., orders-top-city.json)
	â€¢	Schema: {intent, expected: {target, slots{}}, notes}
	â€¢	API: GET /golden/list, POST /golden/add
	â€¢	Trainer (few-shot + weights search):
	â€¢	Module: app/trainer.py
	â€¢	Inputs: feedback.jsonl, golden/
	â€¢	Outputs:
	â€¢	app/checkpoints/trainer_{yyyymmddHHMM}/shaping.json
	â€¢	app/checkpoints/.../fewshot.json
	â€¢	Strategy:
	â€¢	rank-loss on chosenTarget vs candidates
	â€¢	small-grid search over {alias_alpha, shape_alpha, shape_beta, metric_alpha, role_alpha_default}
	â€¢	per-tenant deltas on top of global defaults
	â€¢	Few-Shot Runtime Booster:
	â€¢	File: app/fewshot.py
	â€¢	Loads fewshot.json and nudges role/alias priors at /intent/encode_nl & /synapse/match.
	â€¢	Merge order: global â†’ tenant â†’ request.overrides
	â€¢	Evaluator:
	â€¢	Module: app/eval.py
	â€¢	Metrics: Top-1 acc, MRR, Role hit@1, Slot F1, Aplus mean, PathScore mean
	â€¢	API: GET /trainer/last_eval
	â€¢	Versioning + Rollback:
	â€¢	API: GET /trainer/versions, POST /trainer/activate?ckpt=â€¦, POST /trainer/rollback
	â€¢	Active pointers saved in phase3-neurons/runtime/active.json

â¸»

ğŸ”Œ Public APIs (new)
	â€¢	POST /feedback/record
Body: {intent, chosenTarget, slots?, tenant?} â†’ {ok, id}
	â€¢	POST /trainer/run
Body: {tenant?, maxGrid=64, maxFewshot=2000} â†’ {ok, ckpt, metrics}
	â€¢	POST /trainer/activate
Body: {checkpoint} â†’ {ok, active}
	â€¢	GET /trainer/versions â†’ list of checkpoints + metrics
	â€¢	GET /trainer/last_eval â†’ metrics for active ckpt
	â€¢	GET /fewshot/show?tenant=â€¦ â†’ preview applied few-shot patterns

â¸»

âš™ï¸ Config & Files
	â€¢	shaping.json (trained) â†’ app/checkpoints/.../shaping.json
	â€¢	weights.alias_alpha, shape_alpha, shape_beta, metric_alpha, role_alpha_default
	â€¢	pathScoring.idPrior, fkBonus, lengthPriorBase, cosineWeight
	â€¢	alignPlus.osrZeroWhenNoText

		â€¢	fewshot.json (trained):

		{
  "global": {
    "hints": [{"tokens":["gmv","revenue"], "boost":{"role":"money", "delta":0.03}}],
    "aliases": {"gmv":"revenue"}
  },
  "tenants": {
    "acme": {
      "hints": [{"tokens":["cz"], "boost":{"role":"geo", "delta":0.02}}]
    }
  }
}

	â€¢	runtime/active.json

		{"checkpoint":"trainer_2025-10-28_1405","shaping":"â€¦/shaping.json","fewshot":"â€¦/fewshot.json"}

ğŸ› ï¸ CLI / Make / NPM
	â€¢	make feedback-demo â†’ seeds 20 feedback rows
	â€¢	make trainer-run â†’ runs trainer, prints ckpt + metrics
	â€¢	make trainer-activate CKPT=â€¦
	â€¢	npm run train â†’ POST /trainer/run (global)
	â€¢	npm run train:tenant -- acme
	â€¢	npm run trainer:activate -- trainer_YYYYMMDDHHMM

â¸»

âœ… QA & Validation
	â€¢	Offline eval (mandatory pass gates):
	â€¢	Top-1 accuracy: +â‰¥5% vs baseline or reject
	â€¢	Aplus mean: +â‰¥3% or neutral
	â€¢	No entity drift: PathScore median within Â±10%
	â€¢	AB Shadow:
	â€¢	Header x-experiment: train-shadow returns both baseline & trained scores in debug
	â€¢	Kill-switch: TRAINER_SHADOW_ONLY=true
	â€¢	Canaries:
	â€¢	Tenant allowlist env: TRAINER_TENANT_CANARY="acme,shipyaari"

â¸»

ğŸ” Observability
	â€¢	Structured logs: trainer.run.start/end, trainer.ckpt.activate, fewshot.load
	â€¢	GET /metrics Prom-style gauges:
	â€¢	synapse_trainer_top1_acc{tenant=â€¦}
	â€¢	synapse_trainer_runs_total
	â€¢	synapse_feedback_rows_total

â¸»

ğŸ§¯ Guardrails
	â€¢	Bound weights search ranges (e.g., alias_alpha âˆˆ [0.25, 0.6])
	â€¢	PII filter for feedback payloads (no raw user text stored if marked sensitive)
	â€¢	Tenant isolation: disk paths under checkpoints/{tenant|_global_}/â€¦

â¸»

ğŸš€ Rollout Plan
	1.	Land Feedback Store + /feedback/record.
	2.	Add evaluator on existing golden from Neuron-4 /generate.
	3.	Implement trainer (grid search + few-shot extraction).
	4.	Expose activate/rollback + shadow-AB headers.
	5.	Enable canary tenants only; watch metrics.
	6.	Expand to all tenants; schedule weekly re-train.

â¸»

ğŸ”­ Stretch (optional)
	â€¢	Active Learning: auto-sample low-confidence conflicts into a review queue.
	â€¢	Contrastive Fine-Tuning: learn a small projection on top of the IEM space (kept local).
	â€¢	Meta-Learner: per-ask policy (top_k vs trend) to set shaping weights dynamically.

â¸»


â¸»

6) Planner Integration (A/C/P/S/R with Beam)
	â€¢	âœ… Formula defined; default weights documented.
	â€¢	ğŸŸ¨ Trace shows planner params & slot candidates; missing A/C/P/S/R numbers.
	â€¢	ğŸŸ¨ A(p) partially via cosine (not AlignPlus components).
	â€¢	ğŸŸ¨ C(p) hinted by adapter errors (unindexed ranges) but not scored.
	â€¢	ğŸŸ¨ P(p) simple penalty concept; not consistently applied.
	â€¢	â›” S(p) (alias brittleness) not computed.
	â€¢	â›” R(p) (parity/RBAC) not computed.
	â€¢	â›” Boltzmann exploration (Ï„) in beam selection.

Formula Lab
	â€¢	â›” F3 AlignPlusâ„¢ â†’ A(p)
	â€¢	â›” F8 CostPlusâ„¢ â†’ C(p)
	â€¢	â›” F5 GroupInfoâ„¢ â†’ P(p)
	â€¢	â›” F2 AliasStabilityâ„¢ â†’ S(p)
	â€¢	â›” F7 ParityTauâ„¢ â†’ R(p)

Action: implement neuronScore(plan) and log {A,C,P,S,R,weights,final,Ï„}; wire adapter cost hints.

â¸»

7) Schema Graph & Multi-Join Reasoning
	â€¢	ğŸŸ¨ Single-hop join working (sales_order â†” customer) â€” proven.
	â€¢	â›” Build graph.json (entities + edges: FK=1.0, heuristics<1.0).
	â€¢	â›” find_paths(source,target,max_depth=3) + PathScore ranking.
	â€¢	â›” Join path disambiguation using Aâº/C/S.

Formula Lab
	â€¢	â›” F4 PathScoreâ„¢ (semantics + index + fanout + hop cost).

Action: ship graph builder, path finder, /synapse/paths; add 2-hop cases (ordersâ†’order_itemâ†’product).

â¸»

8) Multi-GroupBy & Complex Query Shapes
	â€¢	âœ… Single & dual groupBy (segmentÃ—country; city over periods).
	â€¢	ğŸŸ¨ Triple groupBy tests (MySQL GROUP BY list, Mongo composite _id) â€” not in suite.
	â€¢	ğŸŸ¨ Compare periods Ã— extra dims (periodÃ—segmentÃ—country) â€” missing tests.
	â€¢	â›” Window functions (moving avg, YoY) â€” defer to Phase-4.
	â€¢	ğŸŸ¨ Nested AND/OR across joins â€” partial coverage.

Formula Lab
	â€¢	â›” F5 GroupInfoâ„¢ (parsimony vs informativeness) to score group sets.

Action: add 3Ã— groupBy examples; AND/OR precedence cases on both engines; log P(p)/InfoGainÌ‚.

â¸»

9) Integration with Phase-2 Runtime
	â€¢	âœ… E2E proven: orders.* (neuron) â†’ sales_order.* UQL/SQL; MySQL & Mongo OK.
	â€¢	âœ… x-intent-vec path works for compile/query.
	â€¢	ğŸŸ¨ Feature flag USE_NEURONS=1 (toggle planner) â€” not plumbed.
	â€¢	ğŸŸ¨ Trace: add A/C/P/S/R everywhere.
	â€¢	â›” Fallback policy (low neuronScore â†’ rule planner + log).

Action: add flag + fallback; propagate Formula Lab values to trace.

â¸»

10) Parity, Index Safety & Policy
	â€¢	âœ… Parity endpoint works; minor ordering diffs acceptable.
	â€¢	âœ… Index guard requireIndexedFilters=true active.
	â€¢	ğŸŸ¨ Feed index/complexity hints into CostPlusâ„¢.
	â€¢	â›” RBAC allowlist + penalties into R(p).

Formula Lab
	â€¢	â›” F7 ParityTauâ„¢ (Kendall Ï„ from sampled parity) â†’ R(p).
	â€¢	â›” F8 CostPlusâ„¢ (unindexed_range, join_depth, like_contains, non_sargable, est_rows).

Action: emit hints from adapters; compute Ï„_K from parity sample; wire to C(p)/R(p).

â¸»

11) Tests & Tooling
	â€¢	âœ… Phase-2 exerciser extended; both engines + extras run.
	â€¢	âœ… Examples validate against schema.
	â€¢	â›” run-phase3-tests.sh invoking neurons: /iem/build, /iem/verify, /intent/encode(_nl), /synapse/match, /synapse/paths, /synapse/fill, /generate.
	â€¢	â›” Assertions: compiled UQL runs; traces contain {A,C,P,S,R,Ï„}; multi-join & 3Ã— groupBy cases; parity Ï„_K present.

Action: add phase-3 runner + summary.

â¸»

12) Documentation & Operability
	â€¢	ğŸŸ¨ Phase-3 Test Report template (like Phase-1/2).
	â€¢	â›” README-neurons.md (how to wire neurons; flags, headers, traces).
	â€¢	â›” Whitepaper appendix: A/C/P/S/R examples & weight sensitivity.

Action: draft report + README + appendix.

â¸»

Immediate Next Actions (surgical)
	1.	Planner scoring & trace: implement neuronScore() with F3/F5/F8; log {A,C,P,S,R,final,Ï„}.
	2.	Graph & paths: build graph.json, add find_paths() + F4 PathScoreâ„¢; ship /synapse/paths.
	3.	/synapse/fill: slot fill + join hints; add 3Ã— groupBy examples.
	4.	Intent NL: /intent/encode_nl + F6 SynoMixâ„¢; load synonyms.json.
	5.	Costs/Parity: adapter hints â†’ F8 CostPlusâ„¢; parity sample â†’ F7 ParityTauâ„¢.
	6.	Phase-3 runner: run-phase3-tests.sh invoking all neuron endpoints; collect traces & parity Ï„_K.


neuron 3 -  upgrade for future
```
Want a quick hardening pass? Three tiny upgrades (no behavioral change unless you use them):
	1.	Per-edge breakdown in /synapse/paths debug
Add an array like:"edgeScores": [
  {"edge":"payment.order_idâ†’orders.id","cosine":0.24,"idPrior":0.10,"fkBonus":0.05,"lengthPrior":0.90,"final":0.3215}
] 
â€¦so you can see why a path scored what it did.
	2.	Normalized score (0â€“1) alongside raw
Return scoreNorm = min(1, max(0, score)) so UI sliders feel consistent across settings.
	3.	Guardrails for overrides
Clamp cosineWeightâˆˆ[0,1], lengthPriorBaseâˆˆ[0.5,1.0], idPrior,fkBonusâˆˆ[0,0.5]. If an override is out of range, echo a warning in debug.warn.

If you like, Iâ€™ll patch those in next. Otherwise we can move on to the next neuron (or wire the tiny Formula Lab â€“ PathScore panel with sliders for cosineWeight / idPrior / fkBonus / lengthPriorBase and live previews).
```

ğŸ’¡ Future: Let Nauvra Learn This

In Phase-4 (Neuro-Symbolic Learning) weâ€™ll train a lightweight Conflict Resolver MLP that:
	â€¢	takes (metricVec, candidateVec, pathFeatures)
	â€¢	learns to predict the most probable relationally consistent slot,
	â€¢	and fine-tunes the weight blend (0.5/0.3/0.2 â†’ learned dynamically).

Thatâ€™s when the resolver becomes self-tuning rather than heuristic.